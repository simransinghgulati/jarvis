{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d39d45b-7376-4d11-814d-a1fbbac5536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4075965-1e65-4293-93ef-b4d628b840b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 27, in <module>\n",
      "    from .chat_template_utils import DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/transformers/utils/chat_template_utils.py\", line 39, in <module>\n",
      "    from torch import Tensor\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/jarvis/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained DialoGPT-medium\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ab55599-8065-4aa6-98f6-9a1904f01433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chat with the model\n",
    "def chat(input_text):\n",
    "    # Encode the input and add EOS token (end of sentence)\n",
    "    new_user_input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # Generate a response from the model\n",
    "    bot_input_ids = new_user_input_ids\n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Decode the model's response and return\n",
    "    bot_response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    \n",
    "    return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e25dce8-0869-452d-b1f3-8cae10734a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm good, you?\n"
     ]
    }
   ],
   "source": [
    "# Example interaction\n",
    "user_input = \"Hello, how are you?\"\n",
    "print(\"Bot:\", chat(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcd5672d-15ad-4227-aa2b-eb69d408077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot():\n",
    "    print(\"Start chatting with the bot (type 'exit' to end)!\")\n",
    "    \n",
    "    # Chat loop\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        bot_response = chat(user_input)\n",
    "        print(\"Bot:\", bot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c6a10a-4f98-45d9-8744-8809a7cb782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the bot (type 'exit' to end)!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hiya\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Who are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I am the one who knocks.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Haha, nice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I know, right? I was like, I know this guy.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What can you do?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I can't do anything.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Then what do you do\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm a software developer.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hm. So am I.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm not sure what you mean by that.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is the date today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: It's the day after the first day of the month.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is the time right now?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: It's currently 11:30 pm EST\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  and in IST?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm not sure what you mean.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is 11:30 pm EST in IST?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: It's 11:30 PM EST.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  How much is 1 USD worth in AUD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: 1 USD 1.00 AUD\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Ok bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm not sure what you mean by that.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Run the chat loop\n",
    "chat_with_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adbe00-8abb-4e9b-aa28-f86aab406fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
